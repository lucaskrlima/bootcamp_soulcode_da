{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnd3rRr89OpX3teP2w9EDc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucaskrlima/bootcamp_soulcode_da/blob/main/Exercicio32_pyspark_LucasLima.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk-Y9d8FnVOu"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "KZUtOdi_EBfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Para deixar a visualição das tabelas mais amigável\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "baC9o6ggEMYw",
        "outputId": "aded368d-e9df-4ebc-dd4a-feffac25cd57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c15cc232da0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://df8a7acc7e59:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 1:\n",
        "Em ambiente PySpark crie uma tabela com quatro atributos sendo o\n",
        "primeiro qualitativo e os demais como quantitivos e dez registros\n",
        "(linhas para a tabela) sem valores nulos.\n",
        "'''\n",
        "\n",
        "'''\n",
        "Criação do schema(esqueleto) em pyspark\n",
        "'''\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DoubleType # importando estrutura da tabela (structType)\n",
        "schema = StructType([ \\\n",
        "    StructField('clube',StringType(),True), \\\n",
        "    StructField('pontos',IntegerType(),True), \\\n",
        "    StructField('vitorias',IntegerType(),True), \\\n",
        "    StructField('gols_marcados', IntegerType(), True), \\\n",
        "  ])\n",
        "\n",
        "'''\n",
        "Criação do objeto (nível Python) 'dados_fut' que contém as tuplas com os regitros que farão\n",
        "parte da tabela\n",
        "'''\n",
        "dados_fut = [('Botafogo',36,12,24),\n",
        "    ('Flamengo',26,8,27),\n",
        "    ('Gremio',26,8,24),\n",
        "    ('Fluminense',24,8,21),\n",
        "    ('Palmeiras',24,6,25),\n",
        "    ('Bragantino',24,6,22),\n",
        "    ('Fortaleza',23,6,16),\n",
        "    ('Sao Paulo',22,6,18),\n",
        "    ('Cruzeiro',21,6,16),\n",
        "    ('Internacional',21,6,13)\n",
        "\n",
        "  ]\n",
        "'''\n",
        "Criação do dataframe py spark passando como parâmetro a estutura da tabela com o objeto\n",
        "que contém os registros\n",
        "'''\n",
        "df_py = spark.createDataFrame(data=dados_fut,schema=schema)\n",
        "'''\n",
        "Imprimi o schema do df_py\n",
        "'''\n",
        "df_py.printSchema()\n",
        "\n",
        "'''\n",
        "Mostrar o df_py\n",
        "'''\n",
        "df_py.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJkRL5oeEYbV",
        "outputId": "8c86dedc-85aa-4657-95d8-77ce944cc581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- clube: string (nullable = true)\n",
            " |-- pontos: integer (nullable = true)\n",
            " |-- vitorias: integer (nullable = true)\n",
            " |-- gols_marcados: integer (nullable = true)\n",
            "\n",
            "+-------------+------+--------+-------------+\n",
            "|        clube|pontos|vitorias|gols_marcados|\n",
            "+-------------+------+--------+-------------+\n",
            "|     Botafogo|    36|      12|           24|\n",
            "|     Flamengo|    26|       8|           27|\n",
            "|       Gremio|    26|       8|           24|\n",
            "|   Fluminense|    24|       8|           21|\n",
            "|    Palmeiras|    24|       6|           25|\n",
            "|   Bragantino|    24|       6|           22|\n",
            "|    Fortaleza|    23|       6|           16|\n",
            "|    Sao Paulo|    22|       6|           18|\n",
            "|     Cruzeiro|    21|       6|           16|\n",
            "|Internacional|    21|       6|           13|\n",
            "+-------------+------+--------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 2:\n",
        "Em ambiente PySpark gerar um describe da tabela gerada no requisito anterior e recebê-lo\n",
        "com um df pyspark.\n",
        "'''\n",
        "df_py.show()\n",
        "\n",
        "df_describe = df_py.describe()\n",
        "\n",
        "#df_describe.show()\n",
        "\n",
        "df_describe = df_describe.drop(\"clube\")\n",
        "\n",
        "df_describe.printSchema()\n",
        "\n",
        "df_describe.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU4FdxtMLZvA",
        "outputId": "36453093-d49f-4fe2-eee4-281bc1954680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+--------+-------------+\n",
            "|        clube|pontos|vitorias|gols_marcados|\n",
            "+-------------+------+--------+-------------+\n",
            "|     Botafogo|    36|      12|           24|\n",
            "|     Flamengo|    26|       8|           27|\n",
            "|       Gremio|    26|       8|           24|\n",
            "|   Fluminense|    24|       8|           21|\n",
            "|    Palmeiras|    24|       6|           25|\n",
            "|   Bragantino|    24|       6|           22|\n",
            "|    Fortaleza|    23|       6|           16|\n",
            "|    Sao Paulo|    22|       6|           18|\n",
            "|     Cruzeiro|    21|       6|           16|\n",
            "|Internacional|    21|       6|           13|\n",
            "+-------------+------+--------+-------------+\n",
            "\n",
            "root\n",
            " |-- summary: string (nullable = true)\n",
            " |-- pontos: string (nullable = true)\n",
            " |-- vitorias: string (nullable = true)\n",
            " |-- gols_marcados: string (nullable = true)\n",
            "\n",
            "+-------+-----------------+-----------------+-----------------+\n",
            "|summary|           pontos|         vitorias|    gols_marcados|\n",
            "+-------+-----------------+-----------------+-----------------+\n",
            "|  count|               10|               10|               10|\n",
            "|   mean|             24.7|              7.2|             20.6|\n",
            "| stddev|4.347413023856831|1.932183566158592|4.623610902506587|\n",
            "|    min|               21|                6|               13|\n",
            "|    max|               36|               12|               27|\n",
            "+-------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 3:\n",
        "Em ambiente PySpark Selecionar a linha de desvio padrão do df gerar uma lista\n",
        "no ambiente python e armazená-lo com o nome sd\n",
        "'''\n",
        "sd = list(df_describe.collect()[2])\n",
        "print(sd)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHD1Yh26MeLx",
        "outputId": "0738ae12-8233-4fbb-8f6a-1624dce1996e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stddev', None, '4.347413023856831', '1.932183566158592', '4.623610902506587']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 4:\n",
        "Em ambiente Python, manipular essa lista e a partir dela gerar uma lista\n",
        "com todos os valores numéricos da lista sd elevado ao quadrado e receber essa\n",
        "nova lista com o nome var\n",
        "'''\n",
        "sd2 = sd[2:5] #gerando uma lista com os valores numéricos\n",
        "sd3 = [float(i) for i in sd2] # convertando os valores da lista anterior de 'str' para 'float'\n",
        "\n",
        "#percorre cada valor da lista anteriror 'sd3' e eleva ao quadrado\n",
        "for n in sd3:\n",
        "  n1 = sd3[0]**2\n",
        "  n2 = sd3[1]**2\n",
        "  n3 = sd3[2]**2\n",
        "\n",
        "var = [n1, n2, n3] #cria uma lista com os valores elevado ao quadrado\n",
        "\n",
        "print(sd3)\n",
        "print(var)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUWBbuETSYP-",
        "outputId": "58817d15-096a-4271-cd27-2370c3bc3eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.347413023856831, 1.932183566158592, 4.623610902506587]\n",
            "[18.89999999999999, 3.733333333333334, 21.377777777777776]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 4:\n",
        "versão professor\n",
        "'''\n",
        "sd.pop(0)\n",
        "print(sd)\n",
        "var = []\n",
        "for i in range(len(sd)):\n",
        "  sd[i] = float(sd[i])\n",
        "  var.append(sd[i]**2)\n",
        "print(var)"
      ],
      "metadata": {
        "id": "oOZUf6e5nTuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e942cc-2233-4a61-f6bc-b40a43ccda77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['4.347413023856831', '1.932183566158592', '4.623610902506587']\n",
            "[18.89999999999999, 3.733333333333334, 21.377777777777776]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 5:\n",
        "Transformar cada lista do requisito anterior em um df py spark\n",
        "'''\n",
        "\n",
        "#Primeira ideia foi criar novamente uma estrutura para cada lista\n",
        "'''\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType # importando estrutura da tabela (structType)\n",
        "schema1 = StructType([ \\\n",
        "    StructField('pontos',DoubleType(),True), \\\n",
        "    StructField('vitorias',DoubleType(),True), \\\n",
        "    StructField('gols_marcados',DoubleType(), True), \\\n",
        "  ])\n",
        "\n",
        "'''\n",
        "#df_py2 = sd3\n",
        "#df_py3 = var\n",
        "\n",
        "#Aqui acontece um erro pois a lista não esta entre colchetes\n",
        "#df_py2 = spark.createDataFrame(sd3)\n",
        "#df_py3 = spark.createDataFrame(var)\n",
        "\n",
        "#Método do professor\n",
        "df_py_sd = spark.createDataFrame(data=[sd3])\n",
        "df_py_var = spark.createDataFrame(data=[var])\n",
        "\n",
        "df_py_sd.show()\n",
        "df_py_var.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ik1tOEudv23",
        "outputId": "2b842b6f-8181-4754-f198-d08afd47e241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+-----------------+\n",
            "|               _1|               _2|               _3|\n",
            "+-----------------+-----------------+-----------------+\n",
            "|4.347413023856831|1.932183566158592|4.623610902506587|\n",
            "+-----------------+-----------------+-----------------+\n",
            "\n",
            "+-----------------+-----------------+------------------+\n",
            "|               _1|               _2|                _3|\n",
            "+-----------------+-----------------+------------------+\n",
            "|18.89999999999999|3.733333333333334|21.377777777777776|\n",
            "+-----------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 5:\n",
        "Transformar cada lista do requisito anterior em um df py spark\n",
        "'''\n",
        "#primeiro converter as listas em tuplas (inferir schema)\n",
        "sd3.insert(0, 'desvio padrao')\n",
        "var.insert(0, 'variancia')\n",
        "\n",
        "sd3 = tuple(sd3)\n",
        "var = tuple(var)\n",
        "\n",
        "var = spark.createDataFrame([var])\n",
        "\n",
        "sd3 = spark.createDataFrame([sd3])\n",
        "\n",
        "var.show()\n",
        "sd3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32kBkdlGmdIW",
        "outputId": "579e3eba-c629-4692-d637-e74b675d742a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+-----------------+------------------+\n",
            "|       _1|               _2|               _3|                _4|\n",
            "+---------+-----------------+-----------------+------------------+\n",
            "|variancia|18.89999999999999|3.733333333333334|21.377777777777776|\n",
            "+---------+-----------------+-----------------+------------------+\n",
            "\n",
            "+-------------+-----------------+-----------------+-----------------+\n",
            "|           _1|               _2|               _3|               _4|\n",
            "+-------------+-----------------+-----------------+-----------------+\n",
            "|desvio padrao|4.347413023856831|1.932183566158592|4.623610902506587|\n",
            "+-------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 6:\n",
        "Em ambiente Pyspark juntar os dois dfs criados no requisito anterior e\n",
        "armazená-lo em um df pyspark chamado sd_var\n",
        "'''\n",
        "\n",
        "df_sd3_var = df_py_sd.union(df_py_var)\n",
        "df_sd3_var.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uVqeRgRsMe5",
        "outputId": "edcfecdb-7ee1-4bb2-da6d-c8fbfb15619e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+------------------+\n",
            "|               _1|               _2|                _3|\n",
            "+-----------------+-----------------+------------------+\n",
            "|4.347413023856831|1.932183566158592| 4.623610902506587|\n",
            "|18.89999999999999|3.733333333333334|21.377777777777776|\n",
            "+-----------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 7:\n",
        "Em ambiente Pyspark gerar uma junção do df da variância com o df das medidas\n",
        "'''\n",
        "df_describe = df_describe.union(var)\n",
        "df_describe.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBQtrdAntfkU",
        "outputId": "e62ec6fe-8108-4635-a854-378affec771b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+-----------------+------------------+\n",
            "|  summary|           pontos|         vitorias|     gols_marcados|\n",
            "+---------+-----------------+-----------------+------------------+\n",
            "|    count|               10|               10|                10|\n",
            "|     mean|             24.7|              7.2|              20.6|\n",
            "|   stddev|4.347413023856831|1.932183566158592| 4.623610902506587|\n",
            "|      min|               21|                6|                13|\n",
            "|      max|               36|               12|                27|\n",
            "|variancia|18.89999999999999|3.733333333333334|21.377777777777776|\n",
            "+---------+-----------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 8:\n",
        "criar uma lista que contenha as modas de todos os atributos quantitativos\n",
        "do df inicial e inseri-la no df pyskar de mesdidas\n",
        "'''\n",
        "\n",
        "[df_py.groupby(i).count().orderBy(\"count\", ascending=False).first()[0] for i in df_py.columns]\n",
        "\n",
        "moda = [df_py.groupby(i).count().orderBy(\"count\", ascending=False).first()[0] for i in df_py.columns]\n",
        "\n",
        "moda.pop(0) #exclui a coluna 'Clube' do df inicial\n",
        "\n",
        "moda.insert(0,'moda') # insere uma linha com nome moda\n",
        "\n",
        "moda = spark.createDataFrame([moda])\n",
        "\n",
        "df_describe = df_describe.union(moda)\n",
        "\n",
        "df_describe.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX2iuKl7xgG4",
        "outputId": "db6f092b-5987-4a10-c5ef-b3896d2d289d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+-----------------+------------------+\n",
            "|  summary|           pontos|         vitorias|     gols_marcados|\n",
            "+---------+-----------------+-----------------+------------------+\n",
            "|    count|               10|               10|                10|\n",
            "|     mean|             24.7|              7.2|              20.6|\n",
            "|   stddev|4.347413023856831|1.932183566158592| 4.623610902506587|\n",
            "|      min|               21|                6|                13|\n",
            "|      max|               36|               12|                27|\n",
            "|variancia|18.89999999999999|3.733333333333334|21.377777777777776|\n",
            "|     moda|               24|                6|                16|\n",
            "|     moda|               24|                6|                16|\n",
            "+---------+-----------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 9:\n",
        "Em ambiente Pyspark e Python e de forma semelhante ao que foi feito nos\n",
        "requisitos anteriores\n",
        "\n",
        "Calcule e adicione ao df de medidas do pyspark as seguintes linhas com seus\n",
        "respectivos valores para as medidas:\n",
        "* Mediana\n",
        "* Q1\n",
        "* Q3\n",
        "* AT\n",
        "* AIQ\n",
        "* LS\n",
        "* LI\n",
        "\n",
        "'''\n",
        "# 1 quartil, mediana e 3 quartil\n",
        "\n",
        "df_py.approxQuantile(['pontos', 'vitorias', 'gols_marcados'], [0.25, 0.5, 0.75], 0 )\n"
      ],
      "metadata": {
        "id": "Ql9MzkCqJOIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ca2d98-c57d-47e7-d36b-f5ab52bc5eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[22.0, 24.0, 26.0], [6.0, 6.0, 8.0], [16.0, 21.0, 24.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fatiando a lista anterior\n",
        "quartis = df_py.approxQuantile(['pontos','vitorias','gols_marcados'], [0.25,0.5,0.75], 0)\n",
        "print(quartis)\n",
        "q1 = [quartis[0][0], quartis[1][0], quartis[2][0]]\n",
        "print(q1)\n",
        "med = [quartis[0][1], quartis[1][1], quartis[2][1]]\n",
        "print(med)\n",
        "q3 = [quartis[0][2], quartis[1][2], quartis[2][2]]\n",
        "print(q3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBa9GBguwQmI",
        "outputId": "ebf4d5a5-0b74-4deb-88e9-482acdc734dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[22.0, 24.0, 26.0], [6.0, 6.0, 8.0], [16.0, 21.0, 24.0]]\n",
            "[22.0, 6.0, 16.0]\n",
            "[24.0, 6.0, 21.0]\n",
            "[26.0, 8.0, 24.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#minimo e máximo\n",
        "min = df_describe.collect()[3]\n",
        "minimo = [float(min['pontos']),float(min['vitorias']),float(min['gols_marcados'])]\n",
        "print(minimo)\n",
        "\n",
        "max = df_describe.collect()[4]\n",
        "maximo = [float(max['pontos']),float(max['vitorias']),float(max['gols_marcados'])]\n",
        "print(maximo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE2xP2nI4eAB",
        "outputId": "3314271e-8d0e-4f38-9230-a449763d183f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21.0, 6.0, 13.0]\n",
            "[36.0, 12.0, 27.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "at = []\n",
        "aiq = []\n",
        "li = []\n",
        "ls = []\n",
        "for i in range(len(minimo)):\n",
        "  at.append(maximo[i]-minimo[i])\n",
        "  aiq.append(q3[i]-q1[i])\n",
        "  li.append(q1[i]-1.5*aiq[i])\n",
        "  ls.append(q3[i]+1.5*aiq[i])\n",
        "\n",
        "q1.insert(0, 'Q1')\n",
        "med.insert(0, 'mediana')\n",
        "q3.insert(0, 'Q3')\n",
        "at.insert(0, 'AT')\n",
        "aiq.insert(0, 'AIQ')\n",
        "li.insert(0, 'LI')\n",
        "ls.insert(0, 'LS')\n",
        "\n",
        "print(q1)\n",
        "print(med)\n",
        "print(q3)\n",
        "print(at)\n",
        "print(aiq)\n",
        "print(li)\n",
        "print(ls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad40EAKV6ZE9",
        "outputId": "0a19eab5-147a-44ed-c66c-3c0eefd6dfb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Q1', 22.0, 6.0, 16.0]\n",
            "['mediana', 24.0, 6.0, 21.0]\n",
            "['Q3', 26.0, 8.0, 24.0]\n",
            "['AT', 15.0, 6.0, 14.0]\n",
            "['AIQ', 4.0, 2.0, 8.0]\n",
            "['LI', 16.0, 3.0, 4.0]\n",
            "['LS', 32.0, 11.0, 36.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Criando um df pyspark com as medidas anteriores\n",
        "adc = spark.createDataFrame([q1,med,q3,at,aiq,li,ls])\n",
        "adc.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY4NnE-QBIQK",
        "outputId": "33ff300b-a361-4fb6-8748-7d81729d6de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----+----+\n",
            "|     _1|  _2|  _3|  _4|\n",
            "+-------+----+----+----+\n",
            "|     Q1|22.0| 6.0|16.0|\n",
            "|mediana|24.0| 6.0|21.0|\n",
            "|     Q3|26.0| 8.0|24.0|\n",
            "|     AT|15.0| 6.0|14.0|\n",
            "|    AIQ| 4.0| 2.0| 8.0|\n",
            "|     LI|16.0| 3.0| 4.0|\n",
            "|     LS|32.0|11.0|36.0|\n",
            "+-------+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unindo a tabela describe com a tabela adc\n",
        "df_describe = df_describe.union(adc)\n",
        "df_describe.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5whsNtQXBfiL",
        "outputId": "e6a9312c-da89-4f48-d98e-9a3864234ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+-----------------+------------------+\n",
            "|  summary|           pontos|         vitorias|     gols_marcados|\n",
            "+---------+-----------------+-----------------+------------------+\n",
            "|    count|               10|               10|                10|\n",
            "|     mean|             24.7|              7.2|              20.6|\n",
            "|   stddev|4.347413023856831|1.932183566158592| 4.623610902506587|\n",
            "|      min|               21|                6|                13|\n",
            "|      max|               36|               12|                27|\n",
            "|variancia|18.89999999999999|3.733333333333334|21.377777777777776|\n",
            "|     moda|               24|                6|                16|\n",
            "|     moda|               24|                6|                16|\n",
            "|       Q1|             22.0|              6.0|              16.0|\n",
            "|  mediana|             24.0|              6.0|              21.0|\n",
            "|       Q3|             26.0|              8.0|              24.0|\n",
            "|       AT|             15.0|              6.0|              14.0|\n",
            "|      AIQ|              4.0|              2.0|               8.0|\n",
            "|       LI|             16.0|              3.0|               4.0|\n",
            "|       LS|             32.0|             11.0|              36.0|\n",
            "|       Q1|             22.0|              6.0|              16.0|\n",
            "|  mediana|             24.0|              6.0|              21.0|\n",
            "|       Q3|             26.0|              8.0|              24.0|\n",
            "|       AT|             15.0|              6.0|              14.0|\n",
            "|      AIQ|              4.0|              2.0|               8.0|\n",
            "+---------+-----------------+-----------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KemykNsYCIyZ"
      }
    }
  ]
}